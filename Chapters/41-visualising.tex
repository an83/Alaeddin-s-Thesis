%checked by Mark May 9th 2019
\section{Proximity and Visual Fidelity}
\label{sec:contacts:visualising}

One of the issues with representing contacts from social networks in AR is how to differentiate between the contacts. In this work \cite{Nassani2017b}, we explored how visual and spatial cues based on social relationships can be used to represent contacts in social AR applications, making it easier to distinguish between them. Previous implementations of social AR have mostly focused on location-based visualisation with no focus on the social relationship to the user. In contrast, this thesis explores how to visualise social relationships in mobile AR environments using proximity and visual fidelity filters. A focus group was organised to explore different options for representing social contacts in a mobile AR application. Also, a user study was conducted to test a head-worn AR prototype using proximity and visual fidelity filters. The study found that filtering social contacts on wearable AR is preferred and useful [REF].  In this section we discuss the results of the focus group and the user study and provide insights into directions for future work.

\begin{figure}[ht]
  \includegraphics[width=\linewidth]{images/mgia17/20170618_031128_HoloLens_cropped}
  \caption{Representing social contacts in AR with different levels of proximity and visual fidelity}
  \label{fig:contacts:overview}
\end{figure}

In this research, we are interested in how to represent a social network with hundreds or thousands of contacts in a wearable AR interface. If there are dozen of virtual tags in an AR view representing people, how can they be distinguished between each other? How will this scale to hundreds or thousands of people? The importance of this research is that it will allow users to view and interact with a large number of social network followers at different levels of privacy and social engagement.

Allowing users to view and interact with a large number of social contacts requires filtering and categorising information. One way to filter/categorise contacts could be to arrange them along a social continuum, depending on how close they are to the user. For example, grouping people into Intimate Family, Friends, Colleagues, and Strangers (see Table \ref{tbl:visual-fidelity-proximity}), or more categories. Contacts from these categories could then be shown as virtual avatars with different levels of visual fidelity and visual proximity, enabling the user to quickly identify people in their social network.

\begin{table}[b]
    \centering
    \caption{Using Visual Fidelity and Visual Proximity to Categorise Friends}
    \label{tbl:visual-fidelity-proximity}
    \begin{tabular}{|l|l|l|}
        \hline
        \textbf{Category} & \textbf{Visual Fidelity}    & \textbf{Visual Proximity}       \\ \hline
        Intimate          & 3D avatar                     & \textless1m, same space  \\ \hline
        Close friend      & 2D avatar                   & 1-5m, close              \\ \hline
        Acquaintance      & Bust image                    & 5-20m, nearby            \\ \hline
        Stranger          & Emoji                        & \textgreater20m, distant \\ \hline
    \end{tabular}
\end{table}


In terms of Visual Fidelity, the representations of people in each of these categories could be increasingly more realistic as the categories changed from Stranger to Intimate Family (see Figure \ref{fig:contacts:visual-fidelity-continuum}). For example, a user may see their spouse as a realistic 3D virtual human superimposed over the real world, but a distant acquaintance would be a simple 2D icon.

\begin{figure}[ht]
    \centering
    \includegraphics[width=.8\linewidth]{images/mgia17/writing-images-07.eps}
    \caption{Changing Visual Fidelity across the social continuum}
    \label{fig:contacts:visual-fidelity-continuum}
\end{figure}

In terms of proximity, previous studies have shown that the distance between people in social settings varies according to their level of intimacy \cite{Anslow2016}. We can use this to place the virtual representations of people in the real world around the user. The people that are intimate family and friends could be shown as visually closer to the user, while people who are strangers would be shown further away (see Figure \ref{fig:contacts:proximic-circles}). This can be implemented as a body-centric virtual information space that travels with the user when they move.

The combination of using Visual Fidelity and Visual Proximity to categorise people from a user's social network could make it significantly easier for the viewer to pay attention to the people that they want to. For example, close friends are represented as life-like virtual avatars near to the user, and so are easily distinguished from strangers that are emoji icons further away.

\begin{figure}[ht]
  \centering
  \includegraphics[width=.8\linewidth]{images/mgia17/writing-images-11.eps}
  \caption{Visual Proxemic \& Visual Fidelity Filtering of Avatars}
    \label{fig:contacts:proximic-circles}
\end{figure}

Other cues could be explored as well, such as placing people closer to the centre of the visual field who are more critical/active, using colour to distinguish which users are currently available, or providing spatial audio cues to guide a person's attention.


\subsection{Implementation}

Using the social continuum metaphor from the previous section, we developed a prototype on the Microsoft HoloLens to represent a user's social contacts in an AR environment. The prototype was built using Unity3D\footnote{https://unity3d.com/} 5.6, HoloToolkit-Unity\footnote{https://github.com/Microsoft/HoloToolkit-Unity}, and 3D avatars from Morph3D\footnote{https://www.morph3d.com/}. 

Figure \ref{fig:contacts:system-diagram} shows an overview of the system components. The prototype uses the HoloLens Spatial Mapping feature to place virtual concentric circles (Circle Manager) on the ground around the user's initial position. On these circles, the social contacts are represented (Friend Manager) by either: a generic person silhouette, a 3D avatar, a 2D image, a bust image, or an emoji. The Scenario Manager controls the overall application, while the Friend Manager controls how friends are rendered. The Circle Manager controls the initial placement of the circles around the user. Spatial Mapping is used to place circles and social contacts on the floor. Morph3D is used for rendering 3D avatars. Figure \ref{fig:contacts:overview} shows the AR view of the user's social network.


\begin{figure}[ht]
  \centering
  \includegraphics[width=.8\linewidth]{images/mgia17/system-diagram.eps}
  \caption{System components}
    \label{fig:contacts:system-diagram}
\end{figure}

To arrange the social network, the user can use hand gestures (e.g., tap and drag) to move a virtual avatar closer or further away from the centre of the circles or change the social group the contact belongs to. The representation of the avatar automatically updates to match the selected social group. For instance, if the user selects a 3D avatar from the Intimate circle and moves it to the Friends circle, then their representation will turn into a bust image to reflect the target social group.

\subsection{Focus Group Evaluation}

To evaluate the interface concept and collect feedback from potential users, we conducted two focus group sessions with a total of 11 participants. The first group consisted of six post-graduate students working on AR/VR research. The second group was a mix of five professional visual graphics and user experience designers who have not worked on AR/VR before. Each session was divided into two activities: (1) user participatory design and (2) a usability test with the prototype. 

The focus group began with a discussion and brainstorming session on how to visualise social network contacts in an AR environment. We briefly introduced the concept of social networking in AR and the challenges observed, such as visual clutter, but no demonstration of the prototype system was given to avoid priming. This activity included three tasks: 

\begin{itemize}
    \item Task 1: Imagine the future of social networks in AR 
    \item Task 2: Map social groups in terms of physical distance 
    \item Task 3: Map social groups in terms of visual fidelity 
\end{itemize}

\textit{Task 1}: We asked participants to draw or describe their vision of the future of how to represent social networks in AR. They then presented their ideas to the group and exchanged feedback.

\textit{Task 2}: We asked participants to order four different social groups (Intimate, Friend, Acquaintance, Stranger) in terms of physical distance from the user. We gave them four silhouettes on paper that had one of the social groups written on the top and asked them to place them on an arrow that had four positions; closest, close, far and farthest.

\textit{Task 3}: We asked the participants to match four different types of visual fidelity (3D avatar, 2D image, Bust image, Emoji) to four social groups (Intimate, Friend, Acquaintance, Stranger). This task included two sets of avatars, male and female.

In the second session, the usability test, we gave a demonstration of the prototype implementation, and asked participants for feedback on the following four conditions (see Figure \ref{fig:contacts:conditions}): 
\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{images/mgia17/conditions-transparent-background}
    \caption{Four conditions for representing social contacts as seen through the HoloLens. Baseline (B): fixed Visual Proximity and Visual Fidelity; Visual Proximity (P): variable Visual Proximity, but fixed Visual Fidelity; Visual Fidelity (V): same Visual Proximity, variable Visual Fidelity, and Combined (C): variable Visual Proximity and Visual Fidelity}
    \label{fig:contacts:conditions}
\end{figure}

\textit{Baseline (B):} all avatars had the same visual representation (silhouette), and they were at the same distance away from the user.

\textit{Visual Proximity (P):} the avatars were placed at different distances from the user based on their social intimacy (the Intimate group was the closest, then Friends, then Acquaintance, then Strangers). However, they were all a silhouette representation with the same Visual Fidelity.

\textit{Visual Fidelity (F):} the avatars were placed at the same distance away from the viewer but had different visual representations based on their social group. The Intimate group was represented by an animated 3D avatar that moved and looked around. Friends were represented by 2D static images, Acquaintances in 2D busts and Strangers were emojis.

\textit{Combined (C):} both proximity and visual fidelity to filter social connections based on their social group.

Each participant tried the four conditions in random order, and for each condition, participants filled out a System Usability Scale (SUS) questionnaire \cite{brooke1996sus}. They also answered the following three personal questions, on a Likert scale from 1 to 7, where 1=\textit{Not very natural/easy} and 7=\textit{Very natural/easy}:

\begin{itemize}
    \item SQ1: How natural was the mapping of proximity to the social relationship?
    \item SQ2: How natural was the mapping of visual fidelity to the social relationship?
    \item SQ3: How easy was it to distinguish between the different avatar types?
\end{itemize}

\subsection{Results}

We recruited 11 participants, four female, aged between 16 and 41 years old, Median=29, SD=5.89. Most (85\%) used social networks (e.g., Facebook, Instagram, Snapchat) daily, and about 60\% reported using AR/VR headsets (e.g., HoloLens, HTC Vive) every month or more often. Only two people reported having no experience with AR/VR headsets before.

\subsection{User Participatory Design}

For \textit{Task 1}, when asked about how they would imagine representing social contacts in an AR platform, there were two main recurring themes, listed in order of popularity.

\textit{Theme 1 - Virtual Avatars}: Display virtual avatars representing friends around the users using spatial cues to distinguish them. The user can interact with other avatars to see their interests, posts or their location. The user can initiate a voice or video call with one of their contacts by interacting with the avatars.

\textit{Theme 2 - Miniatures}: Display miniature avatars (spheres or bubbles) spread around the user environment, each bubble representing a friend. The locations of the bubbles could be determined by the social connection that the user has with that contact. Close friends could be placed near the user on a table surface while strangers are on the ground or further away. A user could pick up one of these bubbles and move them from one social group to another. The bubbles could follow the user when he moved to another place/room, and re-arrange themselves according to the surrounding physical environment.

Other themes included seeing what others are seeing from their point of view, and highlighting who is online (coloured) or offline (greyed out) was also mentioned.

% mark: [Do you have a list of all the 11 ideas? Maybe we can include that somehow]

% TODO (Gun): [Add a couple of sentences here (or in the discussion section) about how similar or different were the user's proposed design compared to our design (prototype system).]

For \textit{Task 2} (Figure \ref{fig:contacts:visual-fidelity}), we asked participants to order friend categories based on proximity (distance from the user). Most (90\%) participants ordered the categories as follows: Intimate, Friend, Acquaintance, Stranger on the scale from closest to furthest away from the user. This shows that users associated proximity with intimacy.

\begin{figure}[ht]
    \centering
    \includegraphics[width=.8\linewidth]{images/mgia17/analysis-images-06.eps}
    \caption{Visual Fidelity categorisation for social contacts}
    \label{fig:contacts:visual-fidelity}
\end{figure}

For \textit{Task 3} 
(Figure \ref{fig:contacts:proximity}), we asked participants to categorise four types of visual fidelity. Most participants (73\%) associated 3D avatars with an Intimate relationship, 59\% marked the 2D image as a  Friend, 64\% associated the bust image for Acquaintances, while 45\% marked emoji for Strangers.
% mark: In the discussion section you might want to talk about the outliers

% mark: Maybe put this as a table?

% TODO (Gun): [Add here (or in the discussion section) how the results align with (or different from) our proposed design of the prototype system].

% mark: [It would be good to include comments from the users as to why they organised them in this way]

\begin{figure}[ht]
    \centering
    \includegraphics[width=.8\linewidth]{images/mgia17/analysis-images-01.eps}
    \caption{Proximity categorisation for social contacts}
    \label{fig:contacts:proximity}
\end{figure}

\subsection{Usability}

\begin{figure}[ht]
    \centering
    \includegraphics[width=.8\linewidth]{images/mgia17/analysis-images-02.eps}
    \caption{The System Usability Score. Whiskers indicate standard error.}
    \label{fig:contacts:sus}
\end{figure}
% TODO (Gun): In the figure caption, you should mention what does the whiskers (error bars) represent. BTW, based on the error bars seems you might have had significant results? Any inferential statistics to report here? I would suggest running Aligned Rank Transform Repeated-measure two-way ANOVA. 
% mark: You should label them B,P,F and C
The SUS scores (Figure \ref{fig:contacts:sus}), show conditions B (69), V (69) and C (72) are rated "Good" while B is "OK" (67). This shows a slight increase in usability in the Proximity and Visual Fidelity conditions. To see if this difference was statistically significant, we ran an aligned rank transform on the SUS results in order to run a 2-way repeated measure ANOVA analysis with two factors Proximity and Visual Fidelity. We did not find any significant differences in terms of SUS between Proximity and Visual Fidelity. 

The subjective questionnaire (Figure \ref{fig:contacts:sq2}) shows an increase in how natural people felt the mapping to proximity (SQ1) was in the Proximity condition. We ran a Friedman test and found that there was a statistically significant difference in rating the four conditions, $X^2(2)=18.402,p<0.001$. Post hoc analyses with Wilcoxon signed-rank tests were conducted with a Bonferroni correction applied, resulting in a significance level set at $alpha$=0.008. There was a significant difference between conditions C and B ($Z=-2.687, p=0.007$). However, there were no statistically significant differences between the other conditions.

Similarly, there was an increase in how natural people felt the mapping to visual fidelity (SQ2) was in the Visual Fidelity condition. We ran a Friedman test and found that there was a statistically significant difference in rating the four conditions, $X^2(2)=21.194,p<0.001$. Post hoc analyses with Wilcoxon signed-rank tests were conducted with a Bonferroni correction applied, resulting in a significance level set at $alpha$=0.008. There were significant differences between conditions V and B  ($Z=-2.825, p=0.005$) and between conditions C and B ($Z=-2.820, p=0.005$). However, there were no statistically significant differences between the other conditions.

As for the (SQ3), people felt it was easier to distinguish between different avatars in both the Visual Fidelity and Combined conditions. We ran a Friedman test and found that there was a statistically significant difference in rating the four conditions, $X^2(2)=20.967,p<0.001$. Post hoc analyses with Wilcoxon signed-rank tests were conducted with a Bonferroni correction applied, resulting in a significance level set at $alpha$=0.008. There were significant differences between conditions V and B  ($Z=-2.816, p=0.005$) and between conditions C and B ($Z=-2.829, p=0.005$). However, there were no statistically significant differences between the other conditions.


\begin{figure}[ht]
    \centering
    \includegraphics[width=.8\linewidth]{images/mgia17/analysis-images-05.eps}
    \caption{Subjective questions results by condition by question. Whiskers indicate standard error. *=statistically significant difference}
    \label{fig:contacts:sq2}
\end{figure}

For ranking the conditions (Figure \ref{fig:contacts:ranking}), participants ranked the four conditions from 4 to 1 where four was the most preferred and one the least preferred. Results show that participants preferred conditions V and C over P and B. We ran a Friedman test and found that there was a statistically significant difference in ranking the four conditions, $X^2(2)=15.222,p=0.002$. Post hoc analyses with Wilcoxon signed-rank tests were conducted with a Bonferroni correction applied, resulting in a significance level set at $alpha$=0.008. There was a significant difference between V and B  ($Z=-3.035, p=0.002$). However, there were no statistically significant differences between the other conditions.

\begin{figure}[ht]
    \centering
    \includegraphics[width=.8\linewidth]{images/mgia17/analysis-images-04.eps}
    \caption{Ranking (4=highest, 1=lowest) Whiskers indicate standard error.}
    \label{fig:contacts:ranking}
\end{figure}

\subsection{Discussion}

From the user study, we found that subjects preferred having a filter to represent their social contacts rather than no filter (i.e., Baseline condition). Based on the ranking results, the most preferred filters are the Visual Fidelity and Combined filters, followed by the Proximity filter.
% TODO (Gun) : [Discuss how this is similar to our proposed design or what is the difference? How this would affect further development/design of the social AR interface?]
The subjective questions revealed that each condition was representing the natural mapping/filter of the user's social contacts (i.e., "SQ1-how natural the proximity" scored high in "P" and so on). Participants felt that thet Visual Fidelity condition (V) was the easiest for distinguishing avatars.

In terms of the strengths and weaknesses of each condition, participants did not like the Baseline condition because they could not easily distinguish the avatars. For example, one participant said, "\textit{I cannot distinguish avatar so well, I do not want to look around at everyone at the same distance}". This confirms our original predictions regarding the placing of social contacts.

With the Proximity condition, participants reported positive feedback and an increase in avatar presence but they were not able to adequately distinguish users from each other.  One user said "\textit{I feel more spatial presence}", but another said "\textit{I need to look around more to see what is where.}"
In the Visual Fidelity condition, participants reported that it was easy to distinguish between contacts, but the interface could be improved. One user said "This one felt more comfortable with people at a distance and was easy to tell people apart", while another user said, "Take more visual space for people whom I do not want to interact with."

In the Combined condition, participants reported it was the best because they felt that it was easier to distinguish between avatars. One user said "\textit{More info is available (fidelity + distance)..}"
% , while another said [put 100\% positive quote]   
However, some participants did not like it when the avatars were too close and recommended increasing the minimum distance between the user and the closest circle.

Overall, the results confirmed our hypothesis that users would prefer to have their social contacts filtered out based on their relationship to them. The question is which filter (Proximity or Visual fidelity) is best for each condition. Users seem to prefer either visual fidelity of a combination of visual fidelity and proximity. This may remain a user preference. 

\subsection{Summary}

In this section, we investigated different visualisation options for representing social contacts in a wearable AR interface. We conducted two focus groups to get feedback from potential users about how they would want to organise social contacts in an AR interface. We found that users identified visual representation and spatial cues as common ways to do this. This matched the interface metaphor used to develop a working prototype.

We tested the usability and user preference of four conditions in a prototype AR interface on a HoloLens display: 1) Baseline, 2) Proximity, 3) Visual Fidelity and 4) Combined. Participants indicated that it was useful to have some different visual fidelity representations of their AR social contacts and that combined use of visual fidelity and proximity was also useful.

In the future, we plan to explore and further develop different visual fidelity representations of social contacts (e.g., displaying avatars as miniatures on a nearby surface). We will also investigate different ways to interact with other users in social networks who are either physically collocated or remote.
