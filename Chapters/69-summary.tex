\pagebreak
\section{Social Interactions Summary}

The research question of this chapter was \ref{rq:data}: "How can wearable AR displays be used best for interacting with social contacts and shared social data?". This chapter explored different options of representing social interactions in AR including samples of 1) sharing annotations on a panoramic video, 2) sharing 3D annotation using depth cameras, and 3) sharing 360 panoramic images with annotation and awareness cues. These explorations include user studies that measure the social presence, usability and users' feedback/preference. These interactions can be used on the Social AR Continuum to control the interactions between social contacts and shared data based on social proximity. For instance, for a closer relationship, higher fidelity of social interactions (e.g., 3D annotations and drawing) can be enabled, while lower fidelity (e.g., text list annotations and pointing) is for further away from social proximity relationships.

The user study of annotation on live stream video showed that there is a statistically significant difference in the social presence (in particular perceived message understanding and perceived effective understanding) and usability score when a higher level of detail of interaction and annotation is available for participants. The user study of annotation on 3D depth data showed that there is a statistically significant difference in social presence when using 3D annotation. 

The last user study explored different interaction methods including drawing and pointing as a higher fidelity interaction method aiming to increase social presence. However, the social presence was not increased due to a limitation of the interaction method on the device chosen (Glass) for this experiment.

The following chapter will summarise the conclusions of the entire thesis and highlight a few future directions from this research.
